We examined the training performance of the DistilBERT model on the
Stanford Sentiment Treebank-2 dataset, focusing on training times across
different platforms and comparing the efficiency of various training
environments.

Results:

● GPU (NVIDIA Pascal P100 16GB GPU): 92.999 s (around 1.5 minutes)

● Cluster (Dual Intel Xeon E5-2670 2.60GHz processors, 32GB RAM
): 1155.50 s (around 19 min)

● Google Colab: 9673.45 s (161 min)

● Google Colab GPU: 140.006 (around 2 min 20 secs)

● Mac M3 Max: 112.59 s (around 2 min)

